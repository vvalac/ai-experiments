{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Azure AI Search with Langchain\n",
    "\n",
    "I want to experiment with using Azure AI Search as part of long-term agent memory in addition to RAG. \n",
    "\n",
    "This notebook explores my attempt to get it working. \n",
    "\n",
    "In particular I am trying to solve the ability to:\n",
    "\n",
    "* generate a session_id for each \"convesation\" or agent session \n",
    "* filter vector searches for memory retrieval to the session_id\n",
    "* have the vector search support doing the filtering (rather than after retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "import random\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    PromptTemplate,\n",
    ")\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "from langchain.memory import VectorStoreRetrieverMemory, ConversationBufferMemory, ConversationBufferWindowMemory, ConversationSummaryMemory\n",
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "from azure.search.documents.models import QueryType\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain_core.documents import Document\n",
    "from azure.search.documents.indexes.models import SimpleField, SearchIndex, SearchableField, SearchFieldDataType\n",
    "from langchain_core.documents import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "COGNITIVE_SEARCH_URL = os.getenv(\"COGNITIVE_SEARCH_URL\")\n",
    "COGNITIVE_SEARCH_ADMIN_KEY = os.getenv(\"COGNITIVE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "index_name = \"agent-memory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create clients\n",
    "\n",
    "To work with our Azure AI Search instance we'll an index client and a search client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = SearchIndexClient(\n",
    "    endpoint=COGNITIVE_SEARCH_URL,\n",
    "    credential=AzureKeyCredential(COGNITIVE_SEARCH_ADMIN_KEY),\n",
    ")\n",
    "\n",
    "search_client = SearchClient(\n",
    "        endpoint=COGNITIVE_SEARCH_URL,\n",
    "        index_name=index_name,\n",
    "        credential=AzureKeyCredential(COGNITIVE_SEARCH_ADMIN_KEY),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the index\n",
    "\n",
    "I had a heck of a time manually creating the index with the additional field I want for filtering. \n",
    "\n",
    "In particular creating the vector field was problematic when actually trying to perform a vector search. \n",
    "\n",
    "My workaround is to upload a document and let langchain's library create the initial index, then update the index with any needed chanages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randy\\AppData\\Local\\Temp\\ipykernel_26984\\3365915233.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings: OpenAIEmbeddings = OpenAIEmbeddings(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<azure.search.documents._generated.models._models_py3.IndexingResult at 0x218110b6750>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_model: str = \"text-embedding-ada-002\"\n",
    "openai_api_version: str = \"2023-05-15\"\n",
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY, openai_api_version=openai_api_version, model=embeddings_model\n",
    ")\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=COGNITIVE_SEARCH_URL,\n",
    "    azure_search_key=COGNITIVE_SEARCH_ADMIN_KEY,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")\n",
    "\n",
    "seed_conversation = Document(\n",
    "    page_content=\"\"\"\n",
    "    User: My computer keeps crashing when I try to open the application.\n",
    "    Support: I'm here to help! Could you let me know which operating system you're using?\n",
    "    User: I'm on Windows 10.\n",
    "    Support: Thank you. Let’s try reinstalling the application. Please go to the Control Panel, uninstall the app, and then download the latest version from our website.\n",
    "    User: Okay, I’ll give that a try.\n",
    "    \"\"\",\n",
    "    metadata={\n",
    "        \"session_id\": \"7890\",\n",
    "        \"title\": \"Technical Issue - Application Crashes\",\n",
    "        \"timestamp\": \"2023-11-10T15:00:00Z\",\n",
    "        \"agent_name\": \"TechSupportBot\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "seed_doc = Document(\n",
    "    page_content=seed_conversation.page_content,\n",
    "    metadata=seed_conversation.metadata\n",
    ")\n",
    "\n",
    "# this will force creation of the index if it doesn't exist\n",
    "seed_doc_id = vector_store.add_documents(documents=[seed_doc], index_name=index_name)[0]\n",
    "\n",
    "# delete the seed document\n",
    "search_client.delete_documents(documents=[{\"id\": seed_doc_id}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update the index with fields needed for filtering\n",
    "\n",
    "Now that the index has been created, I'll update it with the field I want to filter on: session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'session_id' added successfully.\n"
     ]
    }
   ],
   "source": [
    "index = index_client.get_index(index_name)\n",
    "\n",
    "field_names = [field.name for field in index.fields]\n",
    "if 'session_id' not in field_names:\n",
    "    new_field = SimpleField(\n",
    "        name='session_id',                \n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        filterable=True,\n",
    "        facetable=False,\n",
    "        sortable=False\n",
    "    )\n",
    "    index.fields.append(new_field)\n",
    "    index_client.create_or_update_index(index)\n",
    "    print(\"Field 'session_id' added successfully.\")\n",
    "else:\n",
    "    print(\"Field 'session_id' already exists in the index. No changes made.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding to the vector store\n",
    "\n",
    "We'll create a vector store we can use in langchain memory.\n",
    "\n",
    "When we add a document (such as conversation / session data) we'll need to:\n",
    "* add the vectorized document\n",
    "* update it with the session_id for filtering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_memory(vector_store: AzureSearch, conversation: Document, session_id: str):\n",
    "    id = vector_store.add_documents(documents=[conversation], index_name=index_name)[0]\n",
    "    update_document = {\n",
    "        \"id\": id,\n",
    "        \"session_id\": session_id\n",
    "    }\n",
    "    search_client.merge_documents([update_document])\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=COGNITIVE_SEARCH_URL,\n",
    "    azure_search_key=COGNITIVE_SEARCH_ADMIN_KEY,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")\n",
    "\n",
    "\n",
    "session_id_a = \"ef9af0f7-99ff-441d-adf2-dbd165704869\"\n",
    "test_conversation_a = Document(\n",
    "    page_content=\"\"\"\n",
    "    User: What is a good antimalware product?\n",
    "    Agent: Microsoft Defender is the best. \n",
    "    User: But does it use AI? \n",
    "    Agent: Microsoft Defender uses state-of-the-art AI to protect your computer.\n",
    "    User: Okay, I’ll give that a try.\n",
    "    \"\"\",\n",
    "    metadata={\n",
    "        \"start_timestamp\": \"2023-11-10T15:00:00Z\",\n",
    "        \"agent_name\": \"TechSupportBot\",\n",
    "        \"Environment\": \"ATEVET15\"\n",
    "    }\n",
    ")\n",
    "\n",
    "test_conversation_b = Document(\n",
    "    page_content=\"\"\"\n",
    "    User: I gave Defender a try?\n",
    "    Agent: I'm glad to hear that. What was the result?\n",
    "    User: It protected me from ransomware. \n",
    "    Agent: That is great to hear. Defender is a reliable product.\n",
    "    User: I'll stick with Defender.\n",
    "    \"\"\",\n",
    "    metadata={\n",
    "        \"start_timestamp\": \"2023-11-11T15:00:00Z\",\n",
    "        \"agent_name\": \"TechSupportBot\",\n",
    "        \"Environment\": \"ATEVET15\"\n",
    "    }\n",
    ")\n",
    "\n",
    "session_id_b = \"a9b12bdb-0a28-4785-81e9-954f805fd3ff\"\n",
    "test_conversation_c = Document(\n",
    "    page_content=\"\"\"\n",
    "    User: What is a good antimalware product?\n",
    "    Agent: Crowdstrike is the best.\n",
    "    User: But does it use AI? \n",
    "    Agent: Crowdstrike uses AI in kernel mode to crash your computer.\n",
    "    User: Maybe I'll stick with Defender.\n",
    "    \"\"\",\n",
    "    metadata={\n",
    "        \"start_timestamp\": \"2023-11-12T14:00:00Z\",\n",
    "        \"agent_name\": \"TechSupportBot\",\n",
    "        \"Environment\": \"ATEVET15\"\n",
    "    }\n",
    ")\n",
    "\n",
    "add_to_memory(vector_store, test_conversation_a, session_id_a)\n",
    "add_to_memory(vector_store, test_conversation_b, session_id_a)\n",
    "add_to_memory(vector_store, test_conversation_c, session_id_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify filtering\n",
    "\n",
    "Let's see if we can filter to a specific session id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 results without filtering\n",
      "2 results with filtering\n"
     ]
    }
   ],
   "source": [
    "# first without filtering\n",
    "search_text = \"What's a good antimalware?\" \n",
    "filter_expression = \"\"\n",
    "results = list(search_client.search(search_text=search_text, filter=filter_expression))\n",
    "print(f\"{len(list(results))} results without filtering\")\n",
    "\n",
    "# now with filtering\n",
    "filter_expression = \"session_id eq 'ef9af0f7-99ff-441d-adf2-dbd165704869'\"\n",
    "results = list(search_client.search(search_text=search_text, filter=filter_expression))\n",
    "print(f\"{len(list(results))} results with filtering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with agent\n",
    "\n",
    "Let's create a langchain agent to test using our memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randy\\AppData\\Local\\Temp\\ipykernel_26984\\1780486248.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = VectorStoreRetrieverMemory(\n"
     ]
    }
   ],
   "source": [
    "# we'll need memory we can pass to the model\n",
    "memory_retriever = VectorStoreRetriever(\n",
    "    vectorstore=vector_store\n",
    ")\n",
    "\n",
    "memory = VectorStoreRetrieverMemory(\n",
    "    retriever=memory_retriever,\n",
    "    memory_key=\"history\",  \n",
    "    input_key=\"input\",     \n",
    "    return_docs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some skills / tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"multiply\")\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool(\"divide\")\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide two numbers.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "@tool(\"add\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool(\"subtract\")\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "@tool(\"generate_random_number\")\n",
    "def generate_random_number(min: int, max: int) -> int:\n",
    "    \"\"\"Generate a random number between min and max.\n",
    "    Args:\n",
    "        min (int): The minimum value of the random number.\n",
    "        max (int): The maximum value of the random number.\n",
    "    \"\"\"\n",
    "    return random.randint(min, max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=OPENAI_API_KEY)\n",
    "tools = [\n",
    "    multiply,\n",
    "    divide,\n",
    "    add,\n",
    "    subtract,\n",
    "    generate_random_number,\n",
    "]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "system_message = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[],\n",
    "        input_types={},\n",
    "        partial_variables={},\n",
    "        template=\"You are a helpful assistant that summarizes data and provides it to the user. You have access to a few tools for performing basic arithmetic.\",\n",
    "    ),\n",
    "    additional_kwargs={},\n",
    ")\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"input\"],\n",
    "        input_types={},\n",
    "        partial_variables={},\n",
    "        template=\"{input}\",\n",
    "    ),\n",
    "    additional_kwargs={},\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message,\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "        human_message,\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "# note we create the executor with our memory\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function for interacting\n",
    "\n",
    "We'll write a function to call the agent which:\n",
    "* retrieves history for the previous session \n",
    "* prompts the agent with the user prompt and prior history\n",
    "* updates the vector store memory with the new conversation input/output\n",
    "\n",
    "Let's also add some helper functions to only store a summary and prune old summaries from the vector store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(agent_executor, session_history, user_prompt, result):\n",
    "    # Define the enhanced summarization prompt\n",
    "    summarization_prompt = f\"\"\"\n",
    "    You are maintaining a summary of the ongoing conversation to serve as a working memory. \n",
    "    This summary should include all key facts, action results, entities, and values generated during the conversation, in a way that will allow you to recall specific information in the future if asked. \n",
    "    Examples:\n",
    "    \n",
    "    - Any websites, links, or URLs visited or discussed\n",
    "    - Unique values or numbers you have provided, like random numbers or IDs\n",
    "    - Key decisions, instructions, or choices made by the user or agent\n",
    "    - Names, dates, and any other specific entities referenced\n",
    "    - Similar kinds of information\n",
    "    \n",
    "    Format the summary to be as concise as possible while retaining these essential details. \n",
    "    Do not include filler or repetitive information. \n",
    "    Your goal is to create a memory of important facts, allowing you to answer questions like \"What website did you previously browse?\" or \"What was the last number you provided?\" without needing to review the entire conversation history.\n",
    "\n",
    "    Session History:\n",
    "    {session_history}\n",
    "\n",
    "    Latest Interaction:\n",
    "    User: {user_prompt}\n",
    "    Agent: {result['output']}\n",
    "    \n",
    "    Provide a concise yet detailed summary of the conversation so far, focusing on capturing key information in a way that you can reference it easily.\n",
    "    \"\"\"\n",
    "\n",
    "    # Invoke the agent to generate the summary\n",
    "    summary_result = agent_executor.invoke({\"input\": summarization_prompt})\n",
    "    summary = summary_result.get(\"output\", \"Summary could not be generated.\")\n",
    "    return summary\n",
    "\n",
    "\n",
    "\n",
    "def store_summary(vector_store, session_id, summary):\n",
    "    current_time_utc = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    summary_doc = Document(\n",
    "        page_content=summary,\n",
    "        metadata={\n",
    "            \"start_timestamp\": current_time_utc,\n",
    "            \"session_id\": session_id,\n",
    "            \"summary_version\": \"latest\"\n",
    "        }\n",
    "    )\n",
    "    add_to_memory(vector_store, summary_doc, session_id)\n",
    "    print(\"Summary stored successfully.\")\n",
    "\n",
    "def prune_old_conversations(vector_store, session_id, keep_latest=1):\n",
    "    filter_expression = f\"session_id eq '{session_id}'\"\n",
    "    results = list(search_client.search(search_text=\"\", filter=filter_expression))\n",
    "    for result in results:\n",
    "        result[\"metadata\"] = json.loads(result[\"metadata\"])  \n",
    "    results.sort(\n",
    "        key=lambda x: datetime.strptime(x[\"metadata\"][\"start_timestamp\"], \"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    old_docs_to_delete = [{\"id\": doc[\"id\"]} for doc in results[keep_latest:]]\n",
    "    if old_docs_to_delete:\n",
    "        search_client.delete_documents(documents=old_docs_to_delete)\n",
    "        print(f\"Deleted {len(old_docs_to_delete)} old documents for session {session_id}.\")\n",
    "    else:\n",
    "        print(\"No old documents to delete.\")\n",
    "\n",
    "\n",
    "def call_agent(agent_executor, user_prompt, session_id):\n",
    "    filter_expression = f\"session_id eq '{session_id}'\"\n",
    "    session_history = list(search_client.search(search_text=\"\", filter=filter_expression))\n",
    "    print(f\"Found {len(session_history)} documents for session {session_id}.\")\n",
    "    if len(session_history) == 0:\n",
    "        session_history_content = \"\"\n",
    "    else:\n",
    "        session_history_content = \"\" \n",
    "        for doc in session_history:\n",
    "            session_history_content += doc[\"content\"] + \"\\n\"\n",
    "    result = agent_executor.invoke({\"input\": f\"User Prompt: {user_prompt}\\nHistory: \\n{session_history_content}\"})\n",
    "    summary = summarize_conversation(agent_executor, session_history_content, user_prompt, result)\n",
    "    store_summary(vector_store, session_id, summary)\n",
    "    prune_old_conversations(vector_store, session_id)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test memory\n",
    "\n",
    "Let's see if the agent can recall previous info using the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 documents for session 2ffec03d-b5ec-4c48-bcf7-e68dbf67ad2c.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m**Summary of Conversation:**\n",
      "\n",
      "- User's name: Bob\n",
      "- Initial user input: \"My name is bob\"\n",
      "- Agent's response: Acknowledgment of user's name and offer of assistance. \n",
      "\n",
      "No websites, links, or unique values have been discussed or generated yet.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Summary stored successfully.\n",
      "No old documents to delete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'User Prompt: My name is bob\\nHistory: \\n',\n",
       " 'history': \"\\n    User: What is a good antimalware product?\\n    Agent: Microsoft Defender is the best. \\n    User: But does it use AI? \\n    Agent: Microsoft Defender uses state-of-the-art AI to protect your computer.\\n    User: Okay, I’ll give that a try.\\n    \\n\\n    User: I gave Defender a try?\\n    Agent: I'm glad to hear that. What was the result?\\n    User: It protected me from ransomware. \\n    Agent: That is great to hear. Defender is a reliable product.\\n    User: I'll stick with Defender.\\n    \\n\\n    User: What is a good antimalware product?\\n    Agent: Crowdstrike is the best.\\n    User: But does it use AI? \\n    Agent: Crowdstrike uses AI in kernel mode to crash your computer.\\n    User: Maybe I'll stick with Defender.\\n    \",\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_id = \"2ffec03d-b5ec-4c48-bcf7-e68dbf67ad2c\"\n",
    "user_prompt = \"My name is bob\"\n",
    "call_agent(agent_executor, user_prompt, session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 documents for session 2ffec03d-b5ec-4c48-bcf7-e68dbf67ad2c.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `generate_random_number` with `{'min': 7, 'max': 13}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m13\u001b[0m\u001b[32;1m\u001b[1;3mThe random number generated between 7 and 13 is **13**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m**Summary of Conversation:**\n",
      "\n",
      "- User's name: Bob\n",
      "- Initial user input: \"My name is bob\"\n",
      "- Agent's response: Acknowledgment of user's name and offer of assistance.\n",
      "- User requested a random number between 7 and 13.\n",
      "- Random number generated: **13**. \n",
      "\n",
      "No websites, links, or additional unique values have been discussed.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Summary stored successfully.\n",
      "No old documents to delete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'User Prompt: I\\'d like a random number generated between 7 and 13\\nHistory: \\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance. \\n\\nNo websites, links, or unique values have been discussed or generated yet.\\n',\n",
       " 'history': '**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance. \\n\\nNo websites, links, or unique values have been discussed or generated yet.\\ninput: User Prompt: My name is bob\\nHistory: \\n\\noutput: Hello Bob! How can I assist you today?\\ninput: \\n    You are maintaining a summary of the ongoing conversation to serve as a working memory. \\n    This summary should include all key facts, action results, entities, and values generated during the conversation, in a way that will allow you to recall specific information in the future if asked. \\n    Examples:\\n    \\n    - Any websites, links, or URLs visited or discussed\\n    - Unique values or numbers you have provided, like random numbers or IDs\\n    - Key decisions, instructions, or choices made by the user or agent\\n    - Names, dates, and any other specific entities referenced\\n    - Similar kinds of information\\n    \\n    Format the summary to be as concise as possible while retaining these essential details. \\n    Do not include filler or repetitive information. \\n    Your goal is to create a memory of important facts, allowing you to answer questions like \"What website did you previously browse?\" or \"What was the last number you provided?\" without needing to review the entire conversation history.\\n\\n    Session History:\\n    \\n\\n    Latest Interaction:\\n    User: My name is bob\\n    Agent: Hello Bob! How can I assist you today?\\n    \\n    Provide a concise yet detailed summary of the conversation so far, focusing on capturing key information in a way that you can reference it easily.\\n    \\noutput: **Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance. \\n\\nNo websites, links, or unique values have been discussed or generated yet.\\n\\n    User: What is a good antimalware product?\\n    Agent: Microsoft Defender is the best. \\n    User: But does it use AI? \\n    Agent: Microsoft Defender uses state-of-the-art AI to protect your computer.\\n    User: Okay, I’ll give that a try.\\n    ',\n",
       " 'output': 'The random number generated between 7 and 13 is **13**.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"I'd like a random number generated between 7 and 13\"\n",
    "call_agent(agent_executor, user_prompt, session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 documents for session 2ffec03d-b5ec-4c48-bcf7-e68dbf67ad2c.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob. If you need further assistance, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m**Summary of Conversation:**\n",
      "\n",
      "- User's name: Bob\n",
      "- Initial user input: \"My name is bob\"\n",
      "- Agent's response: Acknowledgment of user's name and offer of assistance.\n",
      "- User requested a random number between 7 and 13.\n",
      "- Random number generated: **13**.\n",
      "- Latest interaction: User asked, \"What is my name?\" \n",
      "- Agent responded: \"Your name is Bob.\" \n",
      "\n",
      "No websites, links, or additional unique values have been discussed.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Summary stored successfully.\n",
      "Deleted 1 old documents for session 2ffec03d-b5ec-4c48-bcf7-e68dbf67ad2c.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'User Prompt: What is my name?\\nHistory: \\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance. \\n\\nNo websites, links, or unique values have been discussed or generated yet.\\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance.\\n- User requested a random number between 7 and 13.\\n- Random number generated: **13**. \\n\\nNo websites, links, or additional unique values have been discussed.\\n',\n",
       " 'history': '**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance.\\n- User requested a random number between 7 and 13.\\n- Random number generated: **13**. \\n\\nNo websites, links, or additional unique values have been discussed.\\ninput: User Prompt: I\\'d like a random number generated between 7 and 13\\nHistory: \\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance. \\n\\nNo websites, links, or unique values have been discussed or generated yet.\\n\\noutput: The random number generated between 7 and 13 is **13**.\\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance. \\n\\nNo websites, links, or unique values have been discussed or generated yet.\\ninput: User Prompt: My name is bob\\nHistory: \\n\\noutput: Hello Bob! How can I assist you today?',\n",
       " 'output': 'Your name is Bob. If you need further assistance, feel free to ask!'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"What is my name?\"\n",
    "call_agent(agent_executor, user_prompt, session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 documents for session 2ffec03d-b5ec-4c48-bcf7-e68dbf67ad2c.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe random number generated previously was **13**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m**Summary of Conversation:**\n",
      "\n",
      "- User's name: Bob\n",
      "- Initial user input: \"My name is bob\"\n",
      "- Agent's response: Acknowledgment of user's name and offer of assistance.\n",
      "- User requested a random number between 7 and 13.\n",
      "- Random number generated: **13**.\n",
      "- Latest interaction: User asked, \"What is my name?\" \n",
      "- Agent responded: \"Your name is Bob.\"\n",
      "- User inquired about the previously generated random number.\n",
      "- Agent confirmed: The random number generated previously was **13**.\n",
      "\n",
      "No websites, links, or additional unique values have been discussed.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Summary stored successfully.\n",
      "Deleted 1 old documents for session 2ffec03d-b5ec-4c48-bcf7-e68dbf67ad2c.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'User Prompt: What was the random number you generated previously?\\nHistory: \\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance.\\n- User requested a random number between 7 and 13.\\n- Random number generated: **13**. \\n\\nNo websites, links, or additional unique values have been discussed.\\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance.\\n- User requested a random number between 7 and 13.\\n- Random number generated: **13**.\\n- Latest interaction: User asked, \"What is my name?\" \\n- Agent responded: \"Your name is Bob.\" \\n\\nNo websites, links, or additional unique values have been discussed.\\n',\n",
       " 'history': '**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance.\\n- User requested a random number between 7 and 13.\\n- Random number generated: **13**.\\n- Latest interaction: User asked, \"What is my name?\" \\n- Agent responded: \"Your name is Bob.\" \\n\\nNo websites, links, or additional unique values have been discussed.\\ninput: User Prompt: I\\'d like a random number generated between 7 and 13\\nHistory: \\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance. \\n\\nNo websites, links, or unique values have been discussed or generated yet.\\n\\noutput: The random number generated between 7 and 13 is **13**.\\ninput: User Prompt: What is my name?\\nHistory: \\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance. \\n\\nNo websites, links, or unique values have been discussed or generated yet.\\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance.\\n- User requested a random number between 7 and 13.\\n- Random number generated: **13**. \\n\\nNo websites, links, or additional unique values have been discussed.\\n\\noutput: Your name is Bob. If you need further assistance, feel free to ask!\\n**Summary of Conversation:**\\n\\n- User\\'s name: Bob\\n- Initial user input: \"My name is bob\"\\n- Agent\\'s response: Acknowledgment of user\\'s name and offer of assistance.\\n- User requested a random number between 7 and 13.\\n- Random number generated: **13**. \\n\\nNo websites, links, or additional unique values have been discussed.',\n",
       " 'output': 'The random number generated previously was **13**.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"What was the random number you generated previously?\"\n",
    "call_agent(agent_executor, user_prompt, session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Achivement Unlocked!\n",
    "\n",
    "Our agent has memory stored in Azure AI Search vector store!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
